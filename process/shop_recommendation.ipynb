{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e38b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline, component\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.tools.tool import Tool\n",
    "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
    "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from pymongo import MongoClient\n",
    "from groq import Groq\n",
    "from functools import partial\n",
    "from typing import List, Annotated\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427b332a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801829c",
   "metadata": {},
   "source": [
    "## ChatGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963563a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GroqChatGenerator:\n",
    "    def __init__(self, model: str = \"llama-3.3-70b-versatile\", api_key: str = None): # type: ignore\n",
    "        self.client = Groq(api_key=api_key or os.environ.get(\"GROQ_API_KEY\"))\n",
    "        self.model = model\n",
    "    \n",
    "    @component.output_types(replies=List[ChatMessage])\n",
    "    def run(self, messages: List[ChatMessage]):\n",
    "        if not messages:\n",
    "            raise ValueError(\"The 'messages' list received by GroqChatGenerator is empty.\")\n",
    "\n",
    "        groq_messages = []\n",
    "        for msg in messages:\n",
    "            content = \"\"\n",
    "            if hasattr(msg, 'content'):\n",
    "                content = msg.content\n",
    "            elif hasattr(msg, 'text'):\n",
    "                content = msg.text\n",
    "\n",
    "            if content and hasattr(msg, 'role'):\n",
    "                role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)\n",
    "                groq_messages.append({\"role\": role.lower(), \"content\": content})\n",
    "\n",
    "        if not groq_messages:\n",
    "            raise ValueError(\n",
    "                \"The 'groq_messages' list is empty after conversion. \"\n",
    "                \"The ChatMessage objects seem to be malformed (missing .role or .content/.text).\"\n",
    "            )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=groq_messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"replies\": [\n",
    "                ChatMessage.from_assistant(response.choices[0].message.content)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "@component\n",
    "class GroqGenerator:\n",
    "    def __init__(self, model: str = \"llama-3.3-70b-versatile\", api_key: str = None): # type: ignore\n",
    "        self.client = Groq(api_key=api_key or os.environ.get(\"GROQ_API_KEY\"))\n",
    "        self.model = model\n",
    "    \n",
    "    @component.output_types(replies=List[str])\n",
    "    def run(self, prompt: str):\n",
    "        if not prompt:\n",
    "            raise ValueError(\"The 'prompt' received by GroqGenerator is empty.\")\n",
    "            \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"replies\": [response.choices[0].message.content]\n",
    "        }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea085f3",
   "metadata": {},
   "source": [
    "## Setup Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6849a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document stores\n",
    "products_document_store = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"smartshopper_store\",\n",
    "    collection_name=\"products\",\n",
    "    vector_search_index=\"vector_index\",\n",
    "    full_text_search_index=\"search_index\",\n",
    ")\n",
    "\n",
    "common_info_document_store = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"smartshopper_store\",\n",
    "    collection_name=\"common_info\",\n",
    "    vector_search_index=\"common_info_vector_index\",\n",
    "    full_text_search_index=\"common_info_search_index\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653641a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products in store: 5\n",
      "Common info in store: 6\n"
     ]
    }
   ],
   "source": [
    "# Chat message store\n",
    "chat_message_store = InMemoryChatMessageStore()\n",
    "chat_message_writer = ChatMessageWriter(chat_message_store)\n",
    "\n",
    "\n",
    "print(f\"Products in store: {products_document_store.count_documents()}\")\n",
    "print(f\"Common info in store: {common_info_document_store.count_documents()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62063c77",
   "metadata": {},
   "source": [
    "## MongoDB Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e942547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDBAtlas:\n",
    "    def __init__(self, mongo_connection_string: str):\n",
    "        self.client = MongoClient(mongo_connection_string)\n",
    "        self.db = self.client.smartshopper_store\n",
    "        self.material_collection = self.db.materials\n",
    "        self.category_collection = self.db.categories\n",
    "\n",
    "    def get_materials(self):\n",
    "        return [doc['name'] for doc in self.material_collection.find()]\n",
    "\n",
    "    def get_categories(self):\n",
    "        return [doc['name'] for doc in self.category_collection.find()]\n",
    "\n",
    "@component\n",
    "class GetMaterials:\n",
    "    def __init__(self):\n",
    "        self.db = MongoDBAtlas(os.environ['MONGO_CONNECTION_STRING'])\n",
    "    \n",
    "    @component.output_types(materials=List[str])\n",
    "    def run(self):\n",
    "        materials = self.db.get_materials()\n",
    "        return {\"materials\": materials}\n",
    "\n",
    "@component  \n",
    "class GetCategories:\n",
    "    def __init__(self):\n",
    "        self.db = MongoDBAtlas(os.environ['MONGO_CONNECTION_STRING'])\n",
    "    \n",
    "    @component.output_types(categories=List[str])\n",
    "    def run(self):\n",
    "        categories = self.db.get_categories()\n",
    "        return {\"categories\": categories}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb941ff",
   "metadata": {},
   "source": [
    "## All Pipeline Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34385fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaphraserPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.memory_retriever = ChatMessageRetriever(chat_message_store)\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(\n",
    "            variables=[\"query\", \"memories\"],\n",
    "            required_variables=[\"query\", \"memories\"],\n",
    "        ))\n",
    "        self.pipeline.add_component(\"generator\", GroqChatGenerator())\n",
    "        self.pipeline.add_component(\"memory_retriever\", self.memory_retriever)\n",
    "\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "    \n",
    "    def run(self, query):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\"You are a helpful assistant that paraphrases user queries based on previous conversations.\"),\n",
    "            ChatMessage.from_user(\"\"\"\n",
    "                Please paraphrase the following query based on the conversation history. \n",
    "                If the conversation history is empty, please return the query as is.\n",
    "                \n",
    "                History:\n",
    "                {% for memory in memories %}\n",
    "                    {{memory.text}}\n",
    "                {% endfor %}\n",
    "                \n",
    "                Query: {{query}}\n",
    "                Answer:\n",
    "                \"\"\")\n",
    "        ]\n",
    "\n",
    "        res = self.pipeline.run(\n",
    "            data={\"prompt_builder\": {\"query\": query, \"template\": messages}},\n",
    "            include_outputs_from=[\"generator\"] # type: ignore\n",
    "        )\n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "142c25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaDataFilterPipeline:\n",
    "    def __init__(self, template):\n",
    "        self.template = template\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"materials\", GetMaterials())\n",
    "        self.pipeline.add_component(\"categories\", GetCategories())\n",
    "        self.pipeline.add_component(\"prompt_builder\", PromptBuilder(\n",
    "            template=self.template,\n",
    "            required_variables=[\"input\", \"materials\", \"categories\"],\n",
    "        ))\n",
    "        self.pipeline.add_component(\"generator\", GroqGenerator())\n",
    "        self.pipeline.connect(\"materials.materials\", \"prompt_builder.materials\")\n",
    "        self.pipeline.connect(\"categories.categories\", \"prompt_builder.categories\")\n",
    "        self.pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "\n",
    "    def run(self, query: str):\n",
    "        res = self.pipeline.run({\"prompt_builder\": {\"input\": query}})\n",
    "        return res[\"generator\"][\"replies\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieveAndGenerateAnswerPipeline:\n",
    "    def __init__(self, chat_message_store, document_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.document_store = document_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder())\n",
    "        self.pipeline.add_component(\"retriever\", MongoDBAtlasEmbeddingRetriever(document_store=document_store, top_k=5))\n",
    "        self.pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(\n",
    "            variables=[\"query\", \"documents\"],\n",
    "            required_variables=[\"query\", \"documents\"]\n",
    "        ))\n",
    "        self.pipeline.add_component(\"generator\", GroqChatGenerator())\n",
    "        \n",
    "        self.pipeline.connect(\"embedder\", \"retriever\")\n",
    "        self.pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "\n",
    "    def run(self, query: str, filter: dict = {}):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\"You are a helpful shop assistant that provides product recommendations.\"),\n",
    "            ChatMessage.from_user(\"\"\"\n",
    "                Generate a list of products that best match the query.\n",
    "\n",
    "                **Query Summary:** {{query}}\n",
    "\n",
    "                **Recommended Products:**\n",
    "                {% if documents|length > 0 %}\n",
    "                {% for product in documents %}\n",
    "                {{loop.index}}. **{{ product.meta.title }}**\n",
    "                   - Price: Rp {{ \"{:,}\".format(product.meta.price) }}\n",
    "                   - Material: {{ product.meta.material }}\n",
    "                   - Category: {{ product.meta.category }}\n",
    "                   - Brand: {{ product.meta.brand }}\n",
    "                   - Why recommended: [Based on product description and user needs]\n",
    "\n",
    "                {% endfor %}\n",
    "                {% else %}\n",
    "                No matching products found for your query.\n",
    "                {% endif %}\n",
    "\n",
    "                Answer:\n",
    "                \"\"\")\n",
    "        ]\n",
    "        \n",
    "        res = self.pipeline.run({\n",
    "            \"embedder\": {\"text\": query},\n",
    "            \"retriever\": {\"filters\": filter},\n",
    "            \"prompt_builder\": {\"query\": query, \"template\": messages}\n",
    "        }, include_outputs_from=[\"generator\"]) # type: ignore\n",
    "        \n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonInfoPipeline:\n",
    "    def __init__(self, document_store):\n",
    "        self.document_store = document_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder())\n",
    "        self.pipeline.add_component(\"retriever\", MongoDBAtlasEmbeddingRetriever(document_store=document_store, top_k=3))\n",
    "        self.pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(\n",
    "            variables=[\"query\", \"documents\"],\n",
    "            required_variables=[\"query\", \"documents\"]\n",
    "        ))\n",
    "        self.pipeline.add_component(\"generator\", GroqChatGenerator())\n",
    "        \n",
    "        self.pipeline.connect(\"embedder\", \"retriever\")\n",
    "        self.pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "\n",
    "    def run(self, query: str):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\"You are a helpful customer service assistant.\"),\n",
    "            ChatMessage.from_user(\"\"\"\n",
    "                Based on the retrieved information, provide a helpful answer to the user's question.\n",
    "\n",
    "                Retrieved Information:\n",
    "                {% for doc in documents %}\n",
    "                **{{ doc.meta.title }}:**\n",
    "                {{ doc.content }}\n",
    "                ---\n",
    "                {% endfor %}\n",
    "\n",
    "                User Question: {{query}}\n",
    "\n",
    "                Please provide a comprehensive and friendly answer:\n",
    "                \"\"\")\n",
    "        ]\n",
    "        \n",
    "        res = self.pipeline.run({\n",
    "            \"embedder\": {\"text\": query},\n",
    "            \"prompt_builder\": {\"query\": query, \"template\": messages}\n",
    "        }, include_outputs_from=[\"generator\"]) # type: ignore\n",
    "        \n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c18890",
   "metadata": {},
   "source": [
    "## Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff4e5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FILTER_TEMPLATE = \"\"\"\n",
    "Based on the user input, create a filter for products using Haystack filter syntax.\n",
    "\n",
    "Available materials: {{materials}}\n",
    "Available categories: {{categories}}\n",
    "\n",
    "IMPORTANT: Use Haystack filter syntax format. Return ONLY valid JSON without markdown formatting.\n",
    "\n",
    "Examples of valid filter syntax:\n",
    "- For category: {\"field\": \"category\", \"operator\": \"in\", \"value\": [\"Electronics\"]}\n",
    "- For material: {\"field\": \"material\", \"operator\": \"in\", \"value\": [\"Cotton\"]}\n",
    "- For price range: {\"field\": \"price\", \"operator\": \">=\", \"value\": 100000}\n",
    "- Multiple filters: {\"operator\": \"AND\", \"conditions\": [{\"field\": \"category\", \"operator\": \"in\", \"value\": [\"Electronics\"]}, {\"field\": \"price\", \"operator\": \"<=\", \"value\": 5000000}]}\n",
    "\n",
    "User input: {{input}}\n",
    "\n",
    "Return only the filter JSON without any markdown or explanation:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed6a9f",
   "metadata": {},
   "source": [
    "## Initialize All Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac1967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing all components...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing all components...\")\n",
    "\n",
    "paraphraser = ParaphraserPipeline(chat_message_store)\n",
    "metadata_filter = MetaDataFilterPipeline(METADATA_FILTER_TEMPLATE)\n",
    "rag_pipeline = RetrieveAndGenerateAnswerPipeline(chat_message_store, products_document_store)\n",
    "common_info_pipeline = CommonInfoPipeline(common_info_document_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf3889",
   "metadata": {},
   "source": [
    "## Tool Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8de91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_filter_format(filter_dict):\n",
    "    \"\"\"Convert simple filter format to Haystack filter format\"\"\"\n",
    "    if not filter_dict:\n",
    "        return {}\n",
    "    \n",
    "    conditions = []\n",
    "    \n",
    "    # Handle category filter\n",
    "    if \"category\" in filter_dict and filter_dict[\"category\"]:\n",
    "        conditions.append({\n",
    "            \"field\": \"category\",\n",
    "            \"operator\": \"in\", \n",
    "            \"value\": filter_dict[\"category\"]\n",
    "        })\n",
    "    \n",
    "    # Handle material filter\n",
    "    if \"material\" in filter_dict and filter_dict[\"material\"]:\n",
    "        conditions.append({\n",
    "            \"field\": \"material\",\n",
    "            \"operator\": \"in\",\n",
    "            \"value\": filter_dict[\"material\"]\n",
    "        })\n",
    "    \n",
    "    # Handle price filter\n",
    "    if \"price\" in filter_dict and isinstance(filter_dict[\"price\"], dict):\n",
    "        price_filter = filter_dict[\"price\"]\n",
    "        if \"$gte\" in price_filter:\n",
    "            conditions.append({\n",
    "                \"field\": \"price\",\n",
    "                \"operator\": \">=\",\n",
    "                \"value\": price_filter[\"$gte\"]\n",
    "            })\n",
    "        if \"$lte\" in price_filter:\n",
    "            conditions.append({\n",
    "                \"field\": \"price\", \n",
    "                \"operator\": \"<=\",\n",
    "                \"value\": price_filter[\"$lte\"]\n",
    "            })\n",
    "    \n",
    "    # Return proper format\n",
    "    if len(conditions) == 0:\n",
    "        return {}\n",
    "    elif len(conditions) == 1:\n",
    "        return conditions[0]\n",
    "    else:\n",
    "        return {\n",
    "            \"operator\": \"AND\",\n",
    "            \"conditions\": conditions\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73324e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate(query: Annotated[str, \"User query for product recommendations\"], \n",
    "                         paraphraser, metadata_filter, rag_pipeline):\n",
    "    \"\"\"Tool for product recommendations with fixed filter handling\"\"\"\n",
    "    print(f\"üîç Processing product query: '{query}'\")\n",
    "    \n",
    "    # Step 1: Paraphrase query based on context\n",
    "    paraphrased_query = paraphraser.run(query)\n",
    "    print(f\"üìù Paraphrased: '{paraphrased_query}'\")\n",
    "    \n",
    "    # Step 2: Generate metadata filter\n",
    "    filter_result = metadata_filter.run(paraphrased_query)\n",
    "    print(f\"üéØ Filter result: {filter_result}\")\n",
    "    \n",
    "    # Extract and normalize filter\n",
    "    filter_dict = {}\n",
    "    try:\n",
    "        # Try to parse as direct JSON first\n",
    "        filter_dict = json.loads(filter_result.strip())\n",
    "        print(f\"‚úÖ Parsed filter (direct): {filter_dict}\")\n",
    "        \n",
    "        # Convert to Haystack format if needed\n",
    "        if not (\"field\" in filter_dict or \"operator\" in filter_dict):\n",
    "            filter_dict = normalize_filter_format(filter_dict)\n",
    "            print(f\"üîÑ Normalized filter: {filter_dict}\")\n",
    "            \n",
    "    except json.JSONDecodeError:\n",
    "        # Try to extract JSON from markdown\n",
    "        try:\n",
    "            json_match = re.search(r'```json\\n(.*?)\\n```', filter_result, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "                filter_dict = json.loads(json_str)\n",
    "                filter_dict = normalize_filter_format(filter_dict)\n",
    "                print(f\"‚úÖ Parsed filter (from markdown): {filter_dict}\")\n",
    "            else:\n",
    "                print(\"‚ÑπÔ∏è No filter applied (parsing failed)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Filter parsing error: {e}\")\n",
    "            filter_dict = {}\n",
    "    \n",
    "    # Step 3: Retrieve and generate recommendations\n",
    "    result = rag_pipeline.run(paraphrased_query, filter_dict)\n",
    "    print(f\"üõçÔ∏è Generated recommendations\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256063d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_information(query: Annotated[str, \"User query about shopping information\"], \n",
    "                          common_info_pipeline):\n",
    "    \"\"\"Tool for common shopping information\"\"\"\n",
    "    print(f\"‚ÑπÔ∏è Processing info query: '{query}'\")\n",
    "    result = common_info_pipeline.run(query)\n",
    "    print(f\"üìã Generated information response\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e6e06",
   "metadata": {},
   "source": [
    "## Test Complete Recommendation System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b06dd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to test the fixed system\"\"\"\n",
    "    print(\"Setting up SmartShopper recommendation system...\")\n",
    "\n",
    "    # Document stores\n",
    "    products_document_store = MongoDBAtlasDocumentStore(\n",
    "        database_name=\"smartshopper_store\",\n",
    "        collection_name=\"products\",\n",
    "        vector_search_index=\"vector_index\",\n",
    "        full_text_search_index=\"search_index\",\n",
    "    )\n",
    "\n",
    "    common_info_document_store = MongoDBAtlasDocumentStore(\n",
    "        database_name=\"smartshopper_store\",\n",
    "        collection_name=\"common_info\",\n",
    "        vector_search_index=\"common_info_vector_index\",\n",
    "        full_text_search_index=\"common_info_search_index\",\n",
    "    )\n",
    "    \n",
    "    # Chat message store\n",
    "    chat_message_store = InMemoryChatMessageStore()\n",
    "    chat_message_writer = ChatMessageWriter(chat_message_store)\n",
    "\n",
    "    print(f\"Products in store: {products_document_store.count_documents()}\")\n",
    "    print(f\"Common info in store: {common_info_document_store.count_documents()}\")\n",
    "\n",
    "    # Initialize all components\n",
    "    print(\"Initializing all components...\")\n",
    "    paraphraser = ParaphraserPipeline(chat_message_store)\n",
    "    metadata_filter = MetaDataFilterPipeline(METADATA_FILTER_TEMPLATE)\n",
    "    rag_pipeline = RetrieveAndGenerateAnswerPipeline(chat_message_store, products_document_store)\n",
    "    common_info_pipeline = CommonInfoPipeline(common_info_document_store)\n",
    "\n",
    "    # Create tools\n",
    "    print(\"Creating tools...\")\n",
    "    product_tool = Tool(\n",
    "        name=\"retrieve_and_generate_recommendation\",\n",
    "        description=\"Get product recommendations based on user queries about shopping for items.\",\n",
    "        function=partial(retrieve_and_generate, \n",
    "                        paraphraser=paraphraser, \n",
    "                        metadata_filter=metadata_filter, \n",
    "                        rag_pipeline=rag_pipeline),\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"User query for products\"}},\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    info_tool = Tool(\n",
    "        name=\"get_common_information\", \n",
    "        description=\"Get information about shipping, payment, returns, and other shopping policies.\",\n",
    "        function=partial(get_common_information, common_info_pipeline=common_info_pipeline),\n",
    "        parameters={\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"User query about shopping information\"}},\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== COMPLETE SYSTEM TESTING ===\")\n",
    "\n",
    "    test_scenarios = [\n",
    "        # Product queries\n",
    "        {\n",
    "            \"type\": \"product\",\n",
    "            \"conversation\": [\n",
    "                \"Hi, I need a new phone\",\n",
    "                \"My budget is around 15 million rupiah\", \n",
    "                \"Show me options with good cameras\"\n",
    "            ]\n",
    "        },\n",
    "        # Mixed queries  \n",
    "        {\n",
    "            \"type\": \"mixed\",\n",
    "            \"conversation\": [\n",
    "                \"I want to buy shoes\",\n",
    "                \"What's your return policy?\",\n",
    "                \"Show me running shoes under 3 million\"\n",
    "            ]\n",
    "        },\n",
    "        # Info queries\n",
    "        {\n",
    "            \"type\": \"info\", \n",
    "            \"conversation\": [\n",
    "                \"How do I make payments?\",\n",
    "                \"What about shipping costs?\",\n",
    "                \"Can I get customer support?\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for scenario_idx, scenario in enumerate(test_scenarios, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"SCENARIO {scenario_idx}: {scenario['type'].upper()} QUERIES\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Clear conversation for each scenario\n",
    "        scenario_chat_store = InMemoryChatMessageStore()\n",
    "        scenario_chat_writer = ChatMessageWriter(scenario_chat_store)\n",
    "        scenario_paraphraser = ParaphraserPipeline(scenario_chat_store)\n",
    "        \n",
    "        # Update tools with new paraphraser for this scenario\n",
    "        scenario_product_tool = Tool(\n",
    "            name=\"retrieve_and_generate_recommendation\",\n",
    "            description=\"Get product recommendations based on user queries about shopping for items.\",\n",
    "            function=partial(retrieve_and_generate, \n",
    "                            paraphraser=scenario_paraphraser, \n",
    "                            metadata_filter=metadata_filter, \n",
    "                            rag_pipeline=rag_pipeline),\n",
    "            parameters={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"User query for products\"}},\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        for turn_idx, user_query in enumerate(scenario['conversation'], 1):\n",
    "            print(f\"\\nTurn {turn_idx}: User: '{user_query}'\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Add user message to memory\n",
    "            scenario_chat_writer.run([ChatMessage.from_user(user_query)])\n",
    "            \n",
    "            # Determine which tool to use (simulate agent decision)\n",
    "            if any(keyword in user_query.lower() for keyword in \n",
    "                   ['show', 'need', 'want', 'buy', 'phone', 'shoes', 'options', 'camera']):\n",
    "                # Use product tool\n",
    "                print(\"ü§ñ Agent Decision: Using product recommendation tool\")\n",
    "                try:\n",
    "                    result = scenario_product_tool.function(user_query)\n",
    "                    print(\"\\nAssistant Response:\")\n",
    "                    print(result[:300] + \"...\" if len(result) > 300 else result)\n",
    "                    # Add assistant response to memory\n",
    "                    scenario_chat_writer.run([ChatMessage.from_assistant(result)])\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error with product tool: {e}\")\n",
    "            else:\n",
    "                # Use info tool  \n",
    "                print(\"ü§ñ Agent Decision: Using common information tool\")\n",
    "                try:\n",
    "                    result = info_tool.function(user_query)\n",
    "                    print(\"\\nAssistant Response:\")\n",
    "                    print(result[:300] + \"...\" if len(result) > 300 else result)\n",
    "                    # Add assistant response to memory\n",
    "                    scenario_chat_writer.run([ChatMessage.from_assistant(result)])\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error with info tool: {e}\")\n",
    "\n",
    "    print(\"\\n\\n‚úÖ Shop recommendation testing completed!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e56641e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up SmartShopper recommendation system...\n",
      "Products in store: 5\n",
      "Common info in store: 6\n",
      "Initializing all components...\n",
      "Creating tools...\n",
      "\n",
      "=== COMPLETE SYSTEM TESTING ===\n",
      "\n",
      "============================================================\n",
      "SCENARIO 1: PRODUCT QUERIES\n",
      "============================================================\n",
      "\n",
      "Turn 1: User: 'Hi, I need a new phone'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using product recommendation tool\n",
      "üîç Processing product query: 'Hi, I need a new phone'\n",
      "üìù Paraphrased: 'You're still looking for a new phone, is there anything specific you're looking for in your new device?'\n",
      "üéØ Filter result: {\"field\": \"category\", \"operator\": \"in\", \"value\": [\"Electronics\"]}\n",
      "‚úÖ Parsed filter (direct): {'field': 'category', 'operator': 'in', 'value': ['Electronics']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõçÔ∏è Generated recommendations\n",
      "\n",
      "Assistant Response:\n",
      "It seems like you're in the market for a new phone. To give you the best recommendations, could you please provide more details about what you're looking for in your new device? For example, are you interested in a specific operating system like Android or iOS? Are there any particular features that...\n",
      "\n",
      "Turn 2: User: 'My budget is around 15 million rupiah'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using common information tool\n",
      "‚ÑπÔ∏è Processing info query: 'My budget is around 15 million rupiah'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Generated information response\n",
      "\n",
      "Assistant Response:\n",
      "Hello! I'd be happy to help you with your query.\n",
      "\n",
      "Since your budget is around 15 million rupiah, you have a wide range of options to choose from on our website. With this budget, you can definitely take advantage of our free shipping offer, which applies to orders above 500,000 rupiah. This means yo...\n",
      "\n",
      "Turn 3: User: 'Show me options with good cameras'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using product recommendation tool\n",
      "üîç Processing product query: 'Show me options with good cameras'\n",
      "üìù Paraphrased: 'You're looking for phone options within your budget of 15 million rupiah that have high-quality cameras. I can help you with that. Based on your previous input, I'll provide you with some recommendations that fit your criteria and have good camera capabilities.'\n",
      "üéØ Filter result: {\"operator\": \"AND\", \"conditions\": [{\"field\": \"category\", \"operator\": \"in\", \"value\": [\"Electronics\"]}, {\"field\": \"price\", \"operator\": \"<=\", \"value\": 15000000}]}\n",
      "‚úÖ Parsed filter (direct): {'operator': 'AND', 'conditions': [{'field': 'category', 'operator': 'in', 'value': ['Electronics']}, {'field': 'price', 'operator': '<=', 'value': 15000000}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõçÔ∏è Generated recommendations\n",
      "\n",
      "Assistant Response:\n",
      "I apologize for the initial result. Let me provide you with some alternative options that might fit your budget of 15 million rupiah and have high-quality cameras.\n",
      "\n",
      "Here are a few recommendations:\n",
      "\n",
      "1. **Samsung Galaxy A72**: This phone features a quad-camera setup with a 64MP primary sensor, 12MP fr...\n",
      "\n",
      "============================================================\n",
      "SCENARIO 2: MIXED QUERIES\n",
      "============================================================\n",
      "\n",
      "Turn 1: User: 'I want to buy shoes'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using product recommendation tool\n",
      "üîç Processing product query: 'I want to buy shoes'\n",
      "üìù Paraphrased: 'You're looking to purchase footwear.'\n",
      "üéØ Filter result: {\"field\": \"category\", \"operator\": \"in\", \"value\": [\"Shoes\"]}\n",
      "‚úÖ Parsed filter (direct): {'field': 'category', 'operator': 'in', 'value': ['Shoes']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõçÔ∏è Generated recommendations\n",
      "\n",
      "Assistant Response:\n",
      "It seems like we don't have any matching products in our database for footwear at the moment. However, I'd be happy to help you find what you're looking for. Can you please provide more information about the type of footwear you're interested in? For example, are you looking for shoes, boots, sneake...\n",
      "\n",
      "Turn 2: User: 'What's your return policy?'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using common information tool\n",
      "‚ÑπÔ∏è Processing info query: 'What's your return policy?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Generated information response\n",
      "\n",
      "Assistant Response:\n",
      "Hello! I'd be happy to help you with our return policy.\n",
      "\n",
      "At our store, we want to ensure that you're completely satisfied with your purchase. If for any reason you're not, you can return your item within 30 days of purchase. To be eligible for a return, please make sure that the item is in its origi...\n",
      "\n",
      "Turn 3: User: 'Show me running shoes under 3 million'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using product recommendation tool\n",
      "üîç Processing product query: 'Show me running shoes under 3 million'\n",
      "üìù Paraphrased: 'Since the conversation history already has a similar query (\"Show me running shoes under 3 million\"), the paraphrased query can be: \n",
      "\n",
      "\"Can you display running shoes that cost less than 3 million, as previously requested?\"'\n",
      "üéØ Filter result: {\"operator\": \"AND\", \"conditions\": [{\"field\": \"category\", \"operator\": \"in\", \"value\": [\"Shoes\"]}, {\"field\": \"price\", \"operator\": \"<\", \"value\": 3000000}]}\n",
      "‚úÖ Parsed filter (direct): {'operator': 'AND', 'conditions': [{'field': 'category', 'operator': 'in', 'value': ['Shoes']}, {'field': 'price', 'operator': '<', 'value': 3000000}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõçÔ∏è Generated recommendations\n",
      "\n",
      "Assistant Response:\n",
      "I apologize for the inconvenience. Unfortunately, we don't have any running shoes that cost less than 3 million in our current inventory. However, I can offer to check our catalog or provide recommendations for similar products that might be of interest to you. Would you like me to suggest some alte...\n",
      "\n",
      "============================================================\n",
      "SCENARIO 3: INFO QUERIES\n",
      "============================================================\n",
      "\n",
      "Turn 1: User: 'How do I make payments?'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using common information tool\n",
      "‚ÑπÔ∏è Processing info query: 'How do I make payments?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Generated information response\n",
      "\n",
      "Assistant Response:\n",
      "I'm happy to help you with your payment options.\n",
      "\n",
      "We offer a variety of convenient payment methods to make your shopping experience with us as smooth as possible. You can choose from the following options:\n",
      "\n",
      "1. **Credit Cards**: We accept Visa and MasterCard, so if you have either of these, you're al...\n",
      "\n",
      "Turn 2: User: 'What about shipping costs?'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using common information tool\n",
      "‚ÑπÔ∏è Processing info query: 'What about shipping costs?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Generated information response\n",
      "\n",
      "Assistant Response:\n",
      "I'd be happy to help you with your question about shipping costs.\n",
      "\n",
      "We're excited to offer free shipping for orders above Rp 500,000, so if your order meets that minimum amount, you won't have to pay a single rupiah for shipping. This applies to both standard and express delivery options.\n",
      "\n",
      "If your or...\n",
      "\n",
      "Turn 3: User: 'Can I get customer support?'\n",
      "----------------------------------------\n",
      "ü§ñ Agent Decision: Using common information tool\n",
      "‚ÑπÔ∏è Processing info query: 'Can I get customer support?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Generated information response\n",
      "\n",
      "Assistant Response:\n",
      "You're looking for customer support. Don't worry, we're here to help. Our customer support team is available to assist you from Monday to Friday, 9AM-6PM WIB. You can reach out to us through various channels, including:\n",
      "\n",
      "* WhatsApp: Just send us a message, and we'll get back to you as soon as possib...\n",
      "\n",
      "\n",
      "‚úÖ Shop recommendation testing completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartshopper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
