{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325fe4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from haystack import Pipeline, component\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from groq import Groq\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ef4f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b6d36d",
   "metadata": {},
   "source": [
    "## Custom Groq Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GroqChatGenerator:\n",
    "    def __init__(self, model: str = \"llama-3.3-70b-versatile\", api_key: str = None): # type: ignore\n",
    "        \"\"\"\n",
    "        Initializes the GroqChatGenerator for chat memory.\n",
    "        Updated to use current, active model.\n",
    "        \n",
    "        Alternative models:\n",
    "        - \"llama-3.1-8b-instant\" (faster, smaller model)\n",
    "        - \"gemma2-9b-it\" (Google's model)\n",
    "        \"\"\"\n",
    "        self.client = Groq(api_key=api_key or os.environ.get(\"GROQ_API_KEY\"))\n",
    "        self.model = model\n",
    "    \n",
    "    @component.output_types(replies=List[ChatMessage])\n",
    "    def run(self, messages: List[ChatMessage]):\n",
    "        if not messages:\n",
    "            raise ValueError(\"The 'messages' list received by GroqChatGenerator is empty.\")\n",
    "        \n",
    "        groq_messages = []\n",
    "        for msg in messages:\n",
    "            content = \"\"\n",
    "            if hasattr(msg, 'content'):\n",
    "                content = msg.content\n",
    "            elif hasattr(msg, 'text'):\n",
    "                content = msg.text\n",
    "            \n",
    "            if content and hasattr(msg, 'role'):\n",
    "                role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)\n",
    "                groq_messages.append({\"role\": role.lower(), \"content\": content})\n",
    "        \n",
    "        if not groq_messages:\n",
    "            raise ValueError(\n",
    "                \"The 'groq_messages' list is empty after conversion. \"\n",
    "                \"The ChatMessage objects seem to be malformed (missing .role or .content/.text).\"\n",
    "            )\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=groq_messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"replies\": [\n",
    "                ChatMessage.from_assistant(response.choices[0].message.content)\n",
    "            ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2a3318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up chat message store...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up chat message store...\")\n",
    "chat_message_store = InMemoryChatMessageStore()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69dab4",
   "metadata": {},
   "source": [
    "## Chat Memory Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c44cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_writer = ChatMessageWriter(chat_message_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059f7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_retriever = ChatMessageRetriever(chat_message_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistoryPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"memory_retriever\", ChatMessageRetriever(chat_message_store))\n",
    "        self.pipeline.add_component(\"prompt_builder\", PromptBuilder(\n",
    "            template=\"\"\"\n",
    "            Previous Conversations history:\n",
    "            {% for memory in memories %}\n",
    "                {{memory.text}}\n",
    "            {% endfor %}\n",
    "            \"\"\",\n",
    "            required_variables=[\"memories\"]\n",
    "        ))\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "\n",
    "    def run(self):\n",
    "        res = self.pipeline.run(\n",
    "            data={},\n",
    "            include_outputs_from=[\"prompt_builder\"] # type: ignore\n",
    "        )\n",
    "        return res[\"prompt_builder\"][\"prompt\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ce71b",
   "metadata": {},
   "source": [
    "### Paraphraser Pipeline (Uses Memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f54d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaphraserPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.memory_retriever = ChatMessageRetriever(chat_message_store)\n",
    "    \n",
    "    def run(self, query):\n",
    "        # Get memory first\n",
    "        memory_result = self.memory_retriever.run()\n",
    "        memories = memory_result.get('messages', [])\n",
    "        \n",
    "        # Build the prompt with memories\n",
    "        history_text = \"\"\n",
    "        for memory in memories:\n",
    "            content = memory.content if hasattr(memory, 'content') else memory.text\n",
    "            role = memory.role.value if hasattr(memory.role, 'value') else str(memory.role)\n",
    "            history_text += f\"{role}: {content}\\n\"\n",
    "        \n",
    "        messages = [\n",
    "            ChatMessage.from_system(\n",
    "                \"You are a helpful assistant that paraphrases user queries based on previous conversations.\"\n",
    "            ),\n",
    "            ChatMessage.from_user(\n",
    "                f\"\"\"\n",
    "                Please paraphrase the following query based on the conversation history provided below. \n",
    "                If the conversation history is empty, please return the query as is.\n",
    "                If there is context from previous conversations, use that to make the query more specific.\n",
    "                \n",
    "                History:\n",
    "                {history_text}\n",
    "                \n",
    "                Query: {query}\n",
    "                \n",
    "                Paraphrased Query:\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Use generator directly\n",
    "        generator = GroqChatGenerator()\n",
    "        result = generator.run(messages)\n",
    "        \n",
    "        response_msg = result[\"replies\"][0]\n",
    "        return response_msg.content if hasattr(response_msg, 'content') else response_msg.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27a66003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing chat memory pipelines...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing chat memory pipelines...\")\n",
    "chat_history_pipeline = ChatHistoryPipeline(chat_message_store)\n",
    "paraphraser_pipeline = ParaphraserPipeline(chat_message_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f75b14c",
   "metadata": {},
   "source": [
    "## Test Chat Memory Functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6109829",
   "metadata": {},
   "source": [
    "### Test 1: Empty Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "398e316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 1: EMPTY MEMORY ===\n",
      "Current message count: 0\n",
      "Chat history (should be empty):\n",
      "'\\n            Previous Conversations history:\\n            \\n            '\n",
      "\n",
      "Original query: 'I need a smartphone'\n",
      "Paraphrased (no context): 'Since the conversation history is not empty, I will paraphrase the query to make it more specific. \n",
      "\n",
      "Paraphrased Query: I'm looking to purchase a new smartphone, can you help me find one that suits my needs?'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEST 1: EMPTY MEMORY ===\")\n",
    "print(\"Current message count:\", len(chat_message_store.messages))\n",
    "\n",
    "history = chat_history_pipeline.run()\n",
    "print(\"Chat history (should be empty):\")\n",
    "print(repr(history))\n",
    "\n",
    "query1 = \"I need a smartphone\"\n",
    "paraphrased1 = paraphraser_pipeline.run(query1)\n",
    "print(f\"\\nOriginal query: '{query1}'\")\n",
    "print(f\"Paraphrased (no context): '{paraphrased1}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744fd23",
   "metadata": {},
   "source": [
    "### Test 2: Add Messages to Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d516d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 2: BUILDING CONVERSATION MEMORY ===\n",
      "Adding conversation messages to memory...\n",
      "Messages in store: 0\n",
      "\n",
      "Chat history:\n",
      "\n",
      "            Previous Conversations history:\n",
      "            \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEST 2: BUILDING CONVERSATION MEMORY ===\")\n",
    "conversation = [\n",
    "    ChatMessage.from_user(\"Hi, I'm looking for a smartphone\"),\n",
    "    ChatMessage.from_assistant(\"Hello! I'd be happy to help you find a smartphone. What's your budget and what features are most important to you?\"),\n",
    "    ChatMessage.from_user(\"My budget is around 15 million rupiah\"),\n",
    "    ChatMessage.from_assistant(\"Great! With a 15 million rupiah budget, you have excellent options. Are you looking for any specific features like camera quality, gaming performance, or battery life?\"),\n",
    "    ChatMessage.from_user(\"I want good camera for photography\"),\n",
    "    ChatMessage.from_assistant(\"Perfect! For photography at your budget, I'd recommend looking at smartphones with advanced camera systems. Let me find some options for you.\")\n",
    "]\n",
    "\n",
    "print(\"Adding conversation messages to memory...\")\n",
    "for msg in conversation:\n",
    "    chat_message_writer.run([msg])\n",
    "\n",
    "print(f\"Messages in store: {len(chat_message_store.messages)}\")\n",
    "\n",
    "history = chat_history_pipeline.run()\n",
    "print(\"\\nChat history:\")\n",
    "print(history[:200] + \"...\" if len(history) > 200 else history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88f11b",
   "metadata": {},
   "source": [
    "### Test 3: Context-Aware Paraphrasing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c66f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 3: CONTEXT-AWARE PARAPHRASING ===\n",
      "\n",
      "Original: 'Show me some options'\n",
      "Paraphrased: 'Since the conversation history is empty except for the query \"Show me some options\", I will return the query as is, but I can make a slight modification to make it more general. \n",
      "\n",
      "Paraphrased Query: Show me some options'\n",
      "\n",
      "Original: 'What about cheaper alternatives?'\n",
      "Paraphrased: 'Since the conversation history is empty, I will return the query as is. \n",
      "\n",
      "Paraphrased Query: What about cheaper alternatives?'\n",
      "\n",
      "Original: 'Any with better cameras?'\n",
      "Paraphrased: 'Since the conversation history is empty except for the query \"Any with better cameras?\", I will return the query as is, but I can make an attempt to make it slightly more specific. \n",
      "\n",
      "Paraphrased Query: Are there any devices or models with improved or higher-quality camera capabilities?'\n",
      "\n",
      "Original: 'I changed my mind, show me laptops'\n",
      "Paraphrased: 'Since the conversation history is not empty, I can use the context to make the query more specific. However, the history only mentions that the user changed their mind and wants to see laptops, but it doesn't provide any additional context. \n",
      "\n",
      "Paraphrased Query: Show me available laptops'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEST 3: CONTEXT-AWARE PARAPHRASING ===\")\n",
    "\n",
    "test_queries = [\n",
    "    \"Show me some options\",\n",
    "    \"What about cheaper alternatives?\",\n",
    "    \"Any with better cameras?\",\n",
    "    \"I changed my mind, show me laptops\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    paraphrased = paraphraser_pipeline.run(query)\n",
    "    print(f\"\\nOriginal: '{query}'\")\n",
    "    print(f\"Paraphrased: '{paraphrased}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800b0f6",
   "metadata": {},
   "source": [
    "### Test 4: Add More Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d97cd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 4: EXPANDING CONVERSATION CONTEXT ===\n",
      "Total messages in store: 0\n",
      "\n",
      "Original: 'How much does it cost?'\n",
      "Paraphrased: 'Since the conversation history is empty, the paraphrased query is: How much does it cost?'\n",
      "\n",
      "Original: 'Is it available?'\n",
      "Paraphrased: 'Since the conversation history is empty, I will return the query as is. \n",
      "\n",
      "Paraphrased Query: Is it available?'\n",
      "\n",
      "Original: 'What's the return policy?'\n",
      "Paraphrased: 'Since the conversation history is empty except for the query itself, the paraphrased query would be the same as the original query. \n",
      "\n",
      "Paraphrased Query: What's the return policy?'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEST 4: EXPANDING CONVERSATION CONTEXT ===\")\n",
    "\n",
    "additional_messages = [\n",
    "    ChatMessage.from_user(\"I like the Samsung option, tell me more about it\"),\n",
    "    ChatMessage.from_assistant(\"The Samsung Galaxy S24 is an excellent choice for photography! It features a triple camera system with advanced AI features. Would you like to know about warranty or delivery options?\"),\n",
    "    ChatMessage.from_user(\"What about delivery?\")\n",
    "]\n",
    "\n",
    "for msg in additional_messages:\n",
    "    chat_message_writer.run([msg])\n",
    "\n",
    "print(f\"Total messages in store: {len(chat_message_store.messages)}\")\n",
    "\n",
    "final_queries = [\n",
    "    \"How much does it cost?\",\n",
    "    \"Is it available?\",\n",
    "    \"What's the return policy?\"\n",
    "]\n",
    "\n",
    "for query in final_queries:\n",
    "    paraphrased = paraphraser_pipeline.run(query)\n",
    "    print(f\"\\nOriginal: '{query}'\")\n",
    "    print(f\"Paraphrased: '{paraphrased}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52a3f6",
   "metadata": {},
   "source": [
    "### Test 5: Memory Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a47b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 5: DIRECT MEMORY RETRIEVAL ===\n",
      "Retrieved 9 messages:\n",
      "1. user: Hi, I'm looking for a smartphone...\n",
      "2. assistant: Hello! I'd be happy to help you find a smartphone....\n",
      "3. user: My budget is around 15 million rupiah...\n",
      "4. assistant: Great! With a 15 million rupiah budget, you have e...\n",
      "5. user: I want good camera for photography...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEST 5: DIRECT MEMORY RETRIEVAL ===\")\n",
    "\n",
    "retrieval_result = chat_message_retriever.run()\n",
    "print(f\"Retrieved {len(retrieval_result['messages'])} messages:\")\n",
    "\n",
    "for i, msg in enumerate(retrieval_result['messages'][:5], 1):\n",
    "    role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)\n",
    "    content = msg.content if hasattr(msg, 'content') else msg.text\n",
    "    print(f\"{i}. {role}: {content[:50]}...\") # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6be44",
   "metadata": {},
   "source": [
    "### Test 6: Clear Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6e8a9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 6: MEMORY MANAGEMENT ===\n",
      "Messages before clear: 0\n",
      "\n",
      "With cleared memory:\n",
      "Original: 'Show me smartphones'\n",
      "Paraphrased: 'Since the conversation history is not empty, I can use the context to make the query more specific. \n",
      "\n",
      "The original query is \"Show me smartphones\". Given that this is the starting point of the conversation, the paraphrased query can be made more specific by adding some general parameters that are often considered when looking for smartphones.\n",
      "\n",
      "Paraphrased Query: Show me available smartphones with their prices and key features.'\n",
      "Messages in new store: 0\n",
      "\n",
      "Chat memory testing completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEST 6: MEMORY MANAGEMENT ===\")\n",
    "\n",
    "print(f\"Messages before clear: {len(chat_message_store.messages)}\")\n",
    "\n",
    "new_chat_store = InMemoryChatMessageStore()\n",
    "new_paraphraser = ParaphraserPipeline(new_chat_store)\n",
    "\n",
    "test_query = \"Show me smartphones\"\n",
    "new_paraphrased = new_paraphraser.run(test_query)\n",
    "print(f\"\\nWith cleared memory:\")\n",
    "print(f\"Original: '{test_query}'\")\n",
    "print(f\"Paraphrased: '{new_paraphrased}'\")\n",
    "\n",
    "print(f\"Messages in new store: {len(new_chat_store.messages)}\")\n",
    "\n",
    "print(\"\\nChat memory testing completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartshopper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
